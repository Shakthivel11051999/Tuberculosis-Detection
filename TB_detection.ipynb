{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgxQOBZqu7Pj",
        "outputId": "19a31239-599c-44b4-a8d0-4de19a9053dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: utils in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\Dell\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6Fiqn_ul7QH",
        "outputId": "aeb16c71-a992-4880-83da-3b8301638a5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.6)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: keras in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->keras-tuner) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->keras-tuner) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
            "[notice] To update, run: C:\\Users\\Dell\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9Z6pnWkuig",
        "outputId": "e6d302ed-c40c-4fec-ed64-614a551253df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_6032\\2465427622.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k3GEwhow5Sq6"
      },
      "outputs": [],
      "source": [
        "# Set the paths to the original dataset and the split dataset\n",
        "data_dir = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\data'\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "test_dir = os.path.join(data_dir, \"test\")\n",
        "\n",
        "# Create the train, validation, and test directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Set the split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Loop through each class (Normal and Tuberculosis)\n",
        "for class_name in [\"Normal\", \"Tuberculosis\"]:\n",
        "    # Create the class directories in the train, validation, and test directories\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "    # Get the list of images for the current class\n",
        "    images = os.listdir(os.path.join(data_dir, class_name))\n",
        "    random.shuffle(images)\n",
        "\n",
        "    # Calculate the number of images for each split\n",
        "    num_train = int(len(images) * train_ratio)\n",
        "    num_val = int(len(images) * val_ratio)\n",
        "    num_test = len(images) - num_train - num_val\n",
        "\n",
        "    # Split the images and move them to the respective directories\n",
        "    train_images = images[:num_train]\n",
        "    val_images = images[num_train:num_train+num_val]\n",
        "    test_images = images[num_train+num_val:]\n",
        "\n",
        "    for image in train_images:\n",
        "        src = os.path.join(data_dir, class_name, image)\n",
        "        dst = os.path.join(train_dir, class_name, image)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    for image in val_images:\n",
        "        src = os.path.join(data_dir, class_name, image)\n",
        "        dst = os.path.join(val_dir, class_name, image)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    for image in test_images:\n",
        "        src = os.path.join(data_dir, class_name, image)\n",
        "        dst = os.path.join(test_dir, class_name, image)\n",
        "        shutil.copyfile(src, dst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QCbW2WXWkw0w"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential([\n",
        "        Conv2D(filters=hp.Int(\"filters_1\", 32, 64, step=32),\n",
        "               kernel_size=hp.Choice(\"kernel_size_1\", [3, 5]),\n",
        "               activation=\"relu\",\n",
        "               input_shape=(150, 150, 3)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(filters=hp.Int(\"filters_2\", 64, 128, step=32),\n",
        "               kernel_size=hp.Choice(\"kernel_size_2\", [3, 5]),\n",
        "               activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(filters=hp.Int(\"filters_3\", 128, 256, step=32),\n",
        "               kernel_size=hp.Choice(\"kernel_size_3\", [3, 5]),\n",
        "               activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(units=hp.Int(\"units\", 128, 256, step=32), activation=\"relu\"),\n",
        "        Dropout(hp.Float(\"dropout\", 0.25, 0.5, step=0.05)),\n",
        "        Dense(2, activation=\"softmax\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"LOG\")),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "data_dir = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\data'\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"val\")\n",
        "test_dir = os.path.join(data_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uEY4aF4moGR3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_dir = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\data\\\\train'\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "test_dir = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\data\\\\test'\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)\n",
        "\n",
        "val_dir = 'C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\data\\\\val'\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8_QDcQghTSRx"
      },
      "outputs": [],
      "source": [
        "# Data augmentation parameters for the training dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,        # Rescale pixel values\n",
        "                                   rotation_range=20,      # Rotate images randomly within a range of -20 to +20 degrees\n",
        "                                   width_shift_range=0.1,  # Shift images horizontally by 10% of the width\n",
        "                                   height_shift_range=0.1, # Shift images vertically by 10% of the height\n",
        "                                   zoom_range=0.1,         # Randomly zoom in or out of the image by a factor of 10%\n",
        "                                   horizontal_flip=True)   # Randomly flip the image horizontally\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQP6L7RgTY3C",
        "outputId": "33299489-6b0c-43b7-fc8e-80c9ddd4872c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3822 images belonging to 2 classes.\n",
            "Found 1159 images belonging to 2 classes.\n",
            "Found 1174 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150, 150), batch_size=32, class_mode=\"binary\")\n",
        "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(150, 150), batch_size=32, class_mode=\"binary\")\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(150, 150), batch_size=32, class_mode=\"binary\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQmcmdc-e2ik",
        "outputId": "2f37e6c9-b8db-4ee6-81a0-88db6541947e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 1 Complete [00h 29m 54s]\n",
            "val_accuracy: 0.9361518621444702\n",
            "\n",
            "Best val_accuracy So Far: 0.9361518621444702\n",
            "Total elapsed time: 00h 29m 54s\n",
            "WARNING:tensorflow:From C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\legacy\\save.py:538: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 329s 3s/step - loss: 0.2781 - accuracy: 0.8579 - val_loss: 0.1307 - val_accuracy: 0.9396\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 142s 1s/step - loss: 0.2711 - accuracy: 0.8791 - val_loss: 0.2432 - val_accuracy: 0.8999\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 156s 1s/step - loss: 0.2528 - accuracy: 0.9014 - val_loss: 0.2029 - val_accuracy: 0.9180\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 151s 1s/step - loss: 0.2454 - accuracy: 0.9053 - val_loss: 0.1752 - val_accuracy: 0.9534\n",
            "37/37 [==============================] - 17s 449ms/step - loss: 0.1833 - accuracy: 0.9506\n"
          ]
        }
      ],
      "source": [
        "tuner = RandomSearch(build_model,\n",
        "                     objective=\"val_accuracy\",\n",
        "                     max_trials=1,\n",
        "                     executions_per_trial=1,\n",
        "                     directory=\"random_search\",\n",
        "                     project_name=\"tb_classification\")\n",
        "\n",
        "tuner.search(train_generator,\n",
        "             epochs=20,\n",
        "             validation_data=val_generator,\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)])\n",
        "\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)])\n",
        "\n",
        "test_loss, test_acc = best_model.evaluate(test_generator)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRR_MQPVn_vg",
        "outputId": "9d6e8b0b-78f1-4611-ed08-19647e7a9078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.1833, Test accuracy: 0.9506\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dell\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Correct variable and path\n",
        "best_model.save(\"C:\\\\Users\\\\Dell\\\\OneDrive\\\\Desktop\\\\TB\\\\TB_model.h5\") \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
